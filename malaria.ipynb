{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a0b74c784b1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer, Dropout, Activation, Flatten, Conv2D\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_images/Parasitized\n",
      "Total images  : Parasitized 13780\n",
      "Training : Parasitized 10335\n",
      "Validation : Parasitized 2756\n",
      "Testing : Parasitized 689\n",
      "cell_images/Uninfected\n",
      "Total images  : Uninfected 13780\n",
      "Training : Uninfected 10335\n",
      "Validation : Uninfected 2756\n",
      "Testing : Uninfected 689\n"
     ]
    }
   ],
   "source": [
    "# creating train / val /test\n",
    "root_dir = 'cell_images/'\n",
    "new_root = 'AllDatasets/'\n",
    "classes = ['Parasitized', 'Uninfected']\n",
    "\n",
    "for cls in classes:\n",
    "    os.makedirs(root_dir + new_root+ 'train/' + cls)\n",
    "    os.makedirs(root_dir +new_root +'val/' + cls)\n",
    "    os.makedirs(root_dir +new_root + 'test/' + cls)\n",
    "    \n",
    "## creating partition of the data after shuffeling\n",
    "\n",
    "for cls in classes:\n",
    "    src = root_dir + cls # folder to copy images from\n",
    "    print(src)\n",
    "\n",
    "    allFileNames = os.listdir(src)\n",
    "    np.random.shuffle(allFileNames)\n",
    "\n",
    "    ## here 0.75 = training ratio , (0.95-0.75) = validation ratio , (1-0.95) =  \n",
    "    ##training ratio  \n",
    "    train_FileNames,val_FileNames,test_FileNames = np.split(np.array(allFileNames),[int(len(allFileNames)*0.75),int(len(allFileNames)*0.95)])\n",
    "\n",
    "    # #Converting file names from array to list\n",
    "\n",
    "    train_FileNames = [src+'/'+ name for name in train_FileNames]\n",
    "    val_FileNames = [src+'/' + name for name in val_FileNames]\n",
    "    test_FileNames = [src+'/' + name for name in test_FileNames]\n",
    "\n",
    "    print('Total images  : '+ cls + ' ' +str(len(allFileNames)))\n",
    "    print('Training : '+ cls + ' '+str(len(train_FileNames)))\n",
    "    print('Validation : '+ cls + ' ' +str(len(val_FileNames)))\n",
    "    print('Testing : '+ cls + ' '+str(len(test_FileNames)))\n",
    "    \n",
    "    ## Copy pasting images to target directory\n",
    "\n",
    "    for name in train_FileNames:\n",
    "        shutil.copy(name, root_dir + new_root+'train/'+cls )\n",
    "\n",
    "\n",
    "    for name in val_FileNames:\n",
    "        shutil.copy(name, root_dir +new_root+'val/'+cls )\n",
    "\n",
    "\n",
    "    for name in test_FileNames:\n",
    "        shutil.copy(name,root_dir + new_root+'test/'+cls )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=128\n",
    "IMG_HEIGHT=128\n",
    "img_folder=r'C:\\Users\\DanilAdmin\\malaria\\cell_images\\AllDatasets\\train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-752beef2157b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg_data_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# extract the image array and class name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\DanilAdmin\\malaria\\cell_images\\AllDatasets\\train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\DanilAdmin\\malaria\\cell_images\\AllDatasets\\val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\DanilAdmin\\malaria\\cell_images\\AllDatasets\\test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-752beef2157b>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(img_folder)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclass_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdir1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mimage_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir1\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "                image_path= os.path.join(img_folder, dir1,  file)\n",
    "                image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
    "                if image is not None:\n",
    "                    image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "                    image=np.array(image)\n",
    "                    image = image.astype('float32')\n",
    "                    image /= 255 \n",
    "                    img_data_array.append(image)\n",
    "                    class_name.append(dir1)\n",
    "    return img_data_array, class_name\n",
    "# extract the image array and class name\n",
    "X_train, Y_train =create_dataset(r'C:\\Users\\DanilAdmin\\malaria\\cell_images\\AllDatasets\\train')\n",
    "X_val, Y_val =create_dataset(r'C:\\Users\\DanilAdmin\\malaria\\cell_images\\AllDatasets\\val')\n",
    "X_test, Y_test =create_dataset(r'C:\\Users\\DanilAdmin\\malaria\\cell_images\\AllDatasets\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Parasitized': 0, 'Uninfected': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dict={k: v for v, k in enumerate(np.unique(Y_train))}\n",
    "target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_val_train=[target_dict[Y_train[i]] for i in range(len(Y_train))]\n",
    "target_val_val=[target_dict[Y_val[i]] for i in range(len(Y_val))]\n",
    "target_val_test=[target_dict[Y_val[i]] for i in range(len(Y_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DanilAdmin\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)),\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), padding='same', activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), padding='same', activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(2,activation=\"softmax\")\n",
    "        ])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20668 samples, validate on 5512 samples\n",
      "Epoch 1/10\n",
      "20668/20668 [==============================] - 644s 31ms/sample - loss: 0.6463 - acc: 0.6359 - val_loss: 0.5350 - val_acc: 0.7569\n",
      "Epoch 2/10\n",
      "20668/20668 [==============================] - 161s 8ms/sample - loss: 0.4807 - acc: 0.8093 - val_loss: 0.3592 - val_acc: 0.8714\n",
      "Epoch 3/10\n",
      "20668/20668 [==============================] - 140s 7ms/sample - loss: 0.3902 - acc: 0.8605 - val_loss: 0.3397 - val_acc: 0.8699\n",
      "Epoch 4/10\n",
      "20668/20668 [==============================] - 148s 7ms/sample - loss: 0.3386 - acc: 0.8808 - val_loss: 0.3340 - val_acc: 0.8692\n",
      "Epoch 5/10\n",
      "20668/20668 [==============================] - 149s 7ms/sample - loss: 0.2783 - acc: 0.9069 - val_loss: 0.2944 - val_acc: 0.8853\n",
      "Epoch 6/10\n",
      "20668/20668 [==============================] - 168s 8ms/sample - loss: 0.2104 - acc: 0.9329 - val_loss: 0.2964 - val_acc: 0.8853\n",
      "Epoch 7/10\n",
      "20668/20668 [==============================] - 166s 8ms/sample - loss: 0.1518 - acc: 0.9535 - val_loss: 0.2935 - val_acc: 0.8870\n",
      "Epoch 8/10\n",
      "20668/20668 [==============================] - 152s 7ms/sample - loss: 0.1101 - acc: 0.9664 - val_loss: 0.2951 - val_acc: 0.8989\n",
      "Epoch 9/10\n",
      "20668/20668 [==============================] - 155s 8ms/sample - loss: 0.0825 - acc: 0.9768 - val_loss: 0.3163 - val_acc: 0.8922\n",
      "Epoch 10/10\n",
      "20668/20668 [==============================] - 152s 7ms/sample - loss: 0.0647 - acc: 0.9818 - val_loss: 0.3680 - val_acc: 0.8857\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=np.array(X_train, np.float32),\n",
    "                    y=np.array(list(map(int,target_val_train)), np.float32), \n",
    "                    batch_size=64, \n",
    "                    epochs=10, \n",
    "                    validation_data=(np.array(X_val, np.float32), np.array(list(map(int,target_val_val)), np.float32))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "20668/20668 [==============================] - 148s 7ms/sample - loss: 0.0482 - acc: 0.9859\n",
      "test loss, test acc: [0.04818031876213677, 0.98587185]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(np.array(X_train, np.float32), np.array(list(map(int,target_val_train)), np.float32), batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
